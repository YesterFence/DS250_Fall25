---
title: "Client Report - The War with Star Wars"
subtitle: "Course DS 250"
author: "Ryan Lee"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import pandas as pd 
import numpy as np
from lets_plot import *
# add the additional libraries you need to import for ML here
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

LetsPlot.setup_html(isolated_frame=True)
```


```{python}
# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html

# Include and execute your code here

# import your data here using pandas and the URL

df = pd.read_csv("https://github.com/fivethirtyeight/data/raw/master/star-wars-survey/StarWars.csv", encoding_errors="ignore")
df.head()

```

## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

_A Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client._

## QUESTION|TASK 1

__Shorten the column names and clean them up for easier use with pandas.__ Provide a table or list that exemplifies how you fixed the names. 

_Here I renamed all the columns of the chart. I made them smaller and easier to understand. Then I made a chart to compare the two._

```{python}
# Include and execute your code here

df.columns = [
    'respondent_id', 'seen_any_starwars', 'starwars_fan', 'seen_epi_1', 'seen_epi_2', 'seen_epi_3',
    'seen_epi_4', 'seen_epi_5', 'seen_epi_6', 'rank_epi_1', 'rank_epi_2', 'rank_epi_3', 
    'rank_epi_4', 'rank_epi_5', 'rank_epi_6', 'han_solo', 'luke_skywalker', 'princess_leia_organa',
    'anakin_skywalker', 'obi_wan_kenobi', 'emperor_palpatine', 'darth_vader', 'lando_calrissian',
    'boba_fett', 'c3po', 'r2d2', 'jar_jar_binks', 'padme_amidala', 'yoda',
    'who_shot_first', 'expanded_universe', 'fan_expanded_universe',
    'fan_star_trek', 'gender', 'age', 'household_income', 'education', 'location'
]

df

column_comparison = pd.DataFrame({
    'Original Names': [
        'respondent_id',
        'Have you seen any of the 6 films in the Star Wars franchise?',
        'Do you consider yourself to be a fan of the Star Wars film franchise?',
        'Which of the following Star Wars films have you seen? (Ep.1)',
        'Unnamed: 4 (Ep.2)',
        'Unnamed: 5 (Ep.3)',
        'Unnamed: 6 (Ep.4)',
        'Unnamed: 7 (Ep.5)',
        'Unnamed: 8 (Ep.6)',
        'Please rank the Star Wars films in order of preference (Ep.1)',
        'Unnamed: 10 (Ep.2)',
        'Unnamed: 11 (Ep.3)',
        'Unnamed: 12 (Ep.4)',
        'Unnamed: 13 (Ep.5)',
        'Unnamed: 14 (Ep.6)',
        'Favorability of character (Han Solo)',
        'Unnamed: 16 (Luke Skywalker)',
        'Unnamed: 17 (Princess Leia)',
        'Unnamed: 18 (Anakin Skywalker)',
        'Unnamed: 19 (Obi-Wan Kenobi)',
        'Unnamed: 20 (Palpatine)',
        'Unnamed: 21 (Darth Vader)',
        'Unnamed: 22 (Lando Calrissian)',
        'Unnamed: 23 (Boba Fett)',
        'Unnamed: 24 (C-3PO)',
        'Unnamed: 25 (R2-D2)',
        'Unnamed: 26 (Jar Jar Binks)',
        'Unnamed: 27 (Padme Amidala)',
        'Unnamed: 28 (Yoda)',
        'Which character shot first?',
        'Are you familiar with the Expanded Universe?',
        'Do you consider yourself to be a fan of the Expanded Universe?',
        'Do you consider yourself to be a fan of the Star Trek franchise?',
        'Gender',
        'Age',
        'Household Income',
        'Education',
        'Location (Census Region)'
    ],
    'New Names': [
        'respondent_id', 'seen_any_starwars', 'starwars_fan', 'seen_epi_1', 'seen_epi_2', 'seen_epi_3',
        'seen_epi_4', 'seen_epi_5', 'seen_epi_6', 'rank_epi_1', 'rank_epi_2', 'rank_epi_3', 
        'rank_epi_4', 'rank_epi_5', 'rank_epi_6', 'han_solo', 'luke_skywalker', 'princess_leia_organa',
        'anakin_skywalker', 'obi_wan_kenobi', 'emperor_palpatine', 'darth_vader', 'lando_calrissian',
        'boba_fett', 'c3po', 'r2d2', 'jar_jar_binks', 'padme_amidala', 'yoda',
        'who_shot_first', 'expanded_universe', 'fan_expanded_universe',
        'fan_star_trek', 'gender', 'age', 'household_income', 'education', 'location'
    ]
})

# Display the resulting table
column_comparison


```


## QUESTION|TASK 2

__Clean and format the data so that it can be used in a machine learning model.__ As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.  
    a. Filter the dataset to respondents that have seen at least one film  
    b. Create a new column that converts the age ranges to a single number. Drop the age range categorical column  
    c. Create a new column that converts the education groupings to a single number. Drop the school categorical column  
    d. Create a new column that converts the income ranges to a single number. Drop the income range categorical column  
    e. Create your target (also known as “y” or “label”) column based on the new income range column  
    f. One-hot encode all remaining categorical columns   

_type your results and analysis here_

```{python}
# Part A.
seen_movies = ['seen_epi_1', 'seen_epi_2', 'seen_epi_3', 'seen_epi_4', 'seen_epi_5', 'seen_epi_6']
df_filtered = df[df[seen_movies].notnull().any(axis=1)]
df_filtered.head()

```

```{python}
# Part B.

df_filtered = df_filtered[df_filtered['age'] != 'Response']

age_sort = {
    '18-29': 24,
    '30-44': 37,
    '45-60': 52,
    '> 60': 65,
    np.nan: None
}

df_filtered['age_range'] = df_filtered['age'].map(age_sort)
df_filtered.drop('age', axis=1, inplace=True)

df_filtered[['respondent_id', 'age_range']].head()


```

```{python}
# Part C. 

education_sort = {
    'Less than high school degree': 1,
    'High school degree': 2,
    'Some college or Associate degree': 3,
    'Bachelor degree': 4,
    'Graduate degree': 5,
    np.nan: None
}

df_filtered['education_numeric'] = df_filtered['education'].map(education_sort)
df_filtered.drop('education', axis=1, inplace=True)
df_filtered[['respondent_id', 'education_numeric']].head()

```

```{python}
# Part D. 
income_sort = {
    '$0 - $24,999': 12500,
    '$25,000 - $49,999': 37500,
    '$50,000 - $99,999': 75000,
    '$100,000 - $149,999': 125000,
    '$150,000+': 150000,
    np.nan: None
}

df_filtered['income_numeric'] = df_filtered['household_income'].map(income_sort)
df_filtered.drop('household_income', axis=1, inplace=True)
df_filtered[['respondent_id', 'income_numeric']].head()


```

```{python}
# Part E. 
df_filtered['income_above_50k'] = df_filtered['income_numeric'].apply(lambda x: 1 if x > 50000 else 0)

df_filtered[['respondent_id', 'income_numeric', 'income_above_50k']].head()

```

```{python}
# Part F. 
categorical_cols = df_filtered.select_dtypes(include=['object']).columns
df_final = pd.get_dummies(df_filtered, columns=categorical_cols, dummy_na=True, drop_first=True)
df_final.head()

```

## QUESTION|TASK 3

__Validate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.__  

_I tried my best to replicate the graphs that were given in the project. I had to take the new column I made earlier and clear out the nulls and Response. Then I organized the way_

```{python}
# Include and execute your code here

```

```{python}
df_clean = (
    df
    .dropna(subset=["who_shot_first"])
    .query("who_shot_first != 'Response'")
)

col = "who_shot_first"

shooting = (
    df_clean[col]
    .value_counts()
    .reset_index(name="count")
    .rename(columns={"index": col})
)

chart_order = ["Han", "Greedo", "I don't understand this question"]

shooting[col] = pd.Categorical(
    shooting[col],
    categories=chart_order,
    ordered=True
)
shooting = shooting.sort_values(col)

total = shooting["count"].sum()
shooting["percent"] = shooting["count"] / total * 100
shooting["percent_label"] = shooting["percent"].round(1).astype(str) + "%"

p = (
    ggplot(shooting, aes(x=col, y="count")) +
    geom_bar(stat="identity", fill="#4C8EDA") +
    geom_text(aes(label="percent_label"), hjust=-0.1, size=12) +
    coord_flip() +
    ggtitle("Who Shot First") +
    theme_minimal()
)

p

```

## QUESTION|TASK 4

__Build a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.__ 

_I used the movies that people have seen to determine if they make over 50k a year. What I find out is that this isn't a reliable way to figure out someones income, but it does show how many people from different income brackets can enjoy movies._

```{python}
# Include and execute your code here
df_filtered['income_above_50k'] = (df_filtered['income_numeric'] > 50000).astype(int)

seen_film = ['seen_epi_1', 'seen_epi_2', 'seen_epi_3',
             'seen_epi_4', 'seen_epi_5', 'seen_epi_6']

df_filtered[seen_film] = df_filtered[seen_film].notna().astype(int)

X = df_filtered[seen_film]
y = df_filtered['income_above_50k']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

model = RandomForestClassifier(n_estimators=200, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

```

---

## STRETCH QUESTION|TASK 1

__Build a machine learning model that predicts whether a person makes more than $50k. With accuracy of at least 65%. Describe your model and report the accuracy.__

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 2

__Validate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.__

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 3

__Create a new column that converts the location groupings to a single number. Drop the location categorical column.__  

_type your results and analysis here_

```{python}
# Include and execute your code here


```

---
